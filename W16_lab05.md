(a) (20 pts) A brief description of the project. Here, I'm looking for a short description: probably 1 sentence, 2-3 at most.


  This project scrapes In-n-Out location data from http://www.in-n-out.com/alllocations.asp and saves it into an ArrayList of InAndOutBurgerLocation objects.



(b) (20 pts) a set of user stories (as a X I can Y so that Z) that describe what the current software in its current state can do.

  As an In-n-out customer I can select a city and input it into the program so that I can get a list of In-n-Out locations in said city.
  As an Entreprenuer I can select a city and see where In-n-out locations already exist so that I can decide where to build In-n-out locations.
  As a developer I can get information about In-n-out locations through this API so that I don't have to implement my own data scraper.


(c) (20 pts) a brief assessment of whether the software runs or not. If it runs, briefly describe what it does,

  The software compiles but it does not run. It can create a javadoc, a Java Archive (.jar), a distribution (tarball, zip, jar, source, and doc distribution).
  However, there is no interface to interact with the code and get In-n-out location information.



(c) (20 pts) a set of user stories (at least 2, but you are encouraged to write up to 4 or more if you can, as many as you think is reasonable) about features that COULD be added to the software to make it more useful, fun, better, etc.

  As a person craving In-n-out I can input my current location (or have it detected), so that I can find the location of the In-n-out closest to me.
  As a person craving In-n-out I can input my current location (or have it detected), so that I can find the location of the In-n-out closest to me.
  As a person from out-of-town, I can find the closest location to me with the best ratings in the area based on customer service and food quality.
  As a person who doesn't eat meat, I can find the closest location that offer vegetarian (or vegan) menu options.
  As a person with a disability, I can find a location with a disability-friendly In-N-Out.
  As a person new to In-N-Out, I can find menu options based on my main fast-food preferences (such as shakes, fries, burgers, etc).


(d) (20 pts) An assessment of the current quality of the README.md. What information could be added to make it easier for the next generation of folks maintaining this code to use the software, and/or maintain the software?

  The current README.md only contains the text, "In n Out scraper". The information could contain information about the implementation of the code:
  
  This file is a data scraper that pull In-n-out location data from the website http://www.in-n-out.com/alllocations.asp and saves it into an InAndOutBurgerDirectory object which
  is implemented as an ArrayList of InAndOutBurgerLocation objects. The methods and parameters should be listed with explanations of their parameters and return values.


(e) (20 pts) An assessment of the current state of the build.xml file. Are there targets that need descriptions? Is there old legacy JWS stuff that needs to be removed? (More on this below).

  The build.xml is organized, however the targets for "compile", "clean", "doc", "test", "dist", "jar", and "sourceDist" need to have descriptions added.
  There are comments for the sections of code that chmod certain directories, and the jar target has a comment that contains a link to a website
  that describes where the code comes from. There isn't any old Legacy JWS stuff that needs to be removed. There is a comment under the "dist" target that
  specifies what directory to save the distribution to:  <!--<fileset dir="${distDest}" includes="**/*" />-->. There is another comment under the "dist" target
  that sets delete to "quiet" when removing the current distribution from the directory that dist saves to:
  <!--<delete quiet="true"> <fileset dir="${sourceDest}" includes="**/*" /></delete>-->
  
  When executing "ant javadoc" the javadoc is not created, instead a default hmtl directory of the lab file is created on the url http://www.cs.ucsb.edu/~hunterbuckhorn/cs56/W11/issues/0000003/javadoc
  
  Everything in the build.xml seems to save into the path "cs56/W11/issues/0000003", this needs to be changed to reflect a new distribution and the
  the directory name, "0000003", could be changed to something more meaningful.


(f) (20 pts) An assessment of the current "issues". Are there enough issues that you could earn 1000 points by working on this project? Are the issues clear in terms of what the expectations are?

1. (200 points) Currently, the program only gets the address of the In-N-Out. Add the feature of truly retrieving the various food items from In-N-Out's listed online menus.
2. (200 + 300 points) Currently, the program compiles, tests, and deploys javadoc, but does not offer the user any functionality. Add a command-line interface and/or GUI that displays the results of the scraping, reconstructing the menu that was scraped.

               Command-line interface - 200 points.
               GUI - 300 points.

3. (~100 points )repo needs a README file instructing both a user and developer, which should at least include:

               run instructions
               (at least) a high level description of how the program works
               an explanation of non-obvious ant targets like "images" or "linenumbers"
               a description of the various files/directories
               project history
               screenshots

The total number of points is 800. There are not enough issues to earn 1000 points. However the various changes that should be made elsewhere
could account for the remaining 200 points. The expectations of what needs to be done for each issue are clear.


(g) (20 pts) A list of additional issues that you may have added, if any. For each, a link to the issue is good enough.

  There are some minor issues in the build.xml that can be changed. More comments on the targets can be added.
  The javadoc has to be built correctly.
  The InAndOutBurgerDirectory class can be improved and made more robust by adding new methods and exception handlers.
  
  The InAndOut.java file constructs an InAndOutBurgerDirectory from a file local to Aaron's Desktop: "file:///Users/Aaron/Desktop/test.html"
  The test.html file is included in the API, however this path needs to be changed to the location of the test.html file with respect to where
  it is located on the machine running this code in order for the constructor to work here.
  
  In the Test.java file, this line of code is called: "InAndOutBurgerDirectory directory = new InAndOutBurgerDirectory("http://www.in-n-out.com/alllocations.asp");"
  This should construct a InAndOutBurgerDirectory object with all the locations on the website being stored in InAndOutBurgerLocation objects. However,
  the url "http://www.in-n-out.com/alllocations.asp" is no longer valid and instead refers to "Page not Found" on the In-n-Out website.
  Since this is a data scraping program, a working exception handler should be implemented to account for webpages being modified or their names/data changing and
  breaking the data scraper.




(h) (100 pts) Most important: an assessment of the actual code. Write a bit about how the code is organized. Are the purposes of the classes, and their methods clear?
Is it obvious how the classes relate to one another? Is the code easy to read and understand? If you had to give someone else that was going to work on the code just
"one screenful of text" to help that programmer get up to speed quickly, what information would you convey?

  The Code is organized into five main files: InAndOut.java, InAndOutBurgerLocation.java, InAndOutBurgerDirectory.java and Test.java.
  
  InAndOutBurgerLocation.java: This file contains the InAndOutBurgerLocation class which is the data type used in the InAndOutBurgerDirectory class
  InAndOutBurgerDirectory.java: This file contains the InAndOutBurgerDirectory class which is the primary object in this API. It stores InAndOutBurgerLocation objects
                                in an ArrayList and provides private methods parse the data from the website into the ArrayList and public methods to access the data.
  InAndOut.java: This file contains a main and a test that prints out all of the locations.
  Test.java: This contains all of the test cases that test the various methods in the InAndOutLocation and InAndOutDirectory classes.
  build.xml: Self Explanatory. Contains targets for compile, doc, test, clean, jar, and all. Definitions of each are located in the build.xml or can be
             printed out the console screen by executing "ant menu".
  
  The code is very easy to read and understand, comments are necessary except for maybe the "private String fetchURLContents(URL location)" method, which uses a BufferedReader and throws
  the exceptions: MalformedURLException and IOException.


(i) (40 pts) Related to code quality, but factored out into a separate issue because it is so important: how is the test coverage? Are there JUnit tests at all?
If so, how much of the project is covered by testing? Are there opportunities to expand test coverage, and if so, how would you go about it?

  The Test Cases have several errors. Many tests are testing getters for values that have not been set and thus shouldn't be tested for.
  
  The Test Cases also try to access the invalid webpage, "http://www.in-n-out.com/alllocations.asp". This immediately causes unintended input to be
  passed to the "private void parseSource(String source)" method which initializes the ArrayList<InAndOutLocations> object, locations, to be initialized
  incorrectly. This invalidates all of the test cases that follow it.
  
  There need to be some test cases that test for urls changing or data being moved into a new format. Any of this will break the data scraper
  and could incorrectly construct the ArrayList<InAndOutLocation> locations variable in the InAndOutDirectory Class.
  
  
  First a method has to be implemented that checks the url content before it is loaded into the InAndOutDirectory object. This is to ensure that
  the right webpage with the In-N-Out location data is being scraped and not a "Page not Found" page or a page 404. This can probably be
  implemented by checking the size of the target page html: it will be larger if the page contains the intended information and smaller if it is
  an error page. Or the page content can be compare to a database of strings that contain strings that would commonly be found on an error page such
  as "Page 404" or "Page not found".
